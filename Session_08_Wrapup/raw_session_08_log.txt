
R version 3.3.3 (2017-03-06) -- "Another Canoe"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> repo='https://cran.rstudio.com';
> if(!require(mgcv)) install.packages('mgcv',repos = repo);
Loading required package: mgcv
Loading required package: nlme
This is mgcv 1.8-16. For overview type 'help("mgcv-package")'.
> if(!require(faraway)) install.packages('faraway',repos = repo);
Loading required package: faraway
> if(!require(visreg)) install.packages('visreg',repos=repo);
Loading required package: visreg
> data(ozone);
> head(ozone);
  O3   vh wind humidity temp  ibh dpg ibt vis doy
1  3 5710    4       28   40 2693 -25  87 250  33
2  5 5700    3       37   45  590 -24 128 100  34
3  5 5760    3       51   54 1450  25 139  60  35
4  6 5720    4       69   35 1568  15 121  60  36
5  4 5790    6       19   45 2631 -33 123 100  37
6  4 5790    3       25   55  554 -28 182 250  38
> if(!require(GGally)) install.package('GGally',repos=repo);
Loading required package: GGally

Attaching package: ‘GGally’

The following object is masked from ‘package:faraway’:

    happy

> ggpairs(transform(ozone,O3=log(O3),dO3=cut(O3,4)),
+         aes(color=dO3),upper=list(continuous='density'));
Error in ggpairs(transform(ozone, O3 = log(O3), dO3 = cut(O3, 4)), aes(color = dO3),  : 
  could not find function "aes"
> library(ggplot)
Error in library(ggplot) : there is no package called ‘ggplot’
> library(ggplot2)
> ggpairs(transform(ozone,O3=log(O3),dO3=cut(O3,4)),
+         aes(color=dO3),upper=list(continuous='density'));
 plot: [11,1] [=============================================----] 92% est: 5s 
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
 plot: [11,2] [=============================================----] 93% est: 4s 
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
 plot: [11,3] [==============================================---] 93% est: 4s 
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
 plot: [11,4] [==============================================---] 94% est: 4s 
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
 plot: [11,5] [===============================================--] 95% est: 3s 
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
 plot: [11,6] [===============================================--] 96% est: 3s 
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
 plot: [11,7] [===============================================--] 97% est: 2s 
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
 plot: [11,8] [================================================-] 98% est: 2s 
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
 plot: [11,9] [================================================-] 98% est: 1s 
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
 plot: [11,10] [================================================] 99% est: 1s 
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
                                                                              
> ?nls
> example(lme)

lme> fm1 <- lme(distance ~ age, data = Orthodont) # random is ~ age

lme> fm2 <- lme(distance ~ age + Sex, data = Orthodont, random = ~ 1)

lme> summary(fm1)
Linear mixed-effects model fit by REML
 Data: Orthodont 
       AIC      BIC    logLik
  454.6367 470.6173 -221.3183

Random effects:
 Formula: ~age | Subject
 Structure: General positive-definite
            StdDev    Corr  
(Intercept) 2.3270339 (Intr)
age         0.2264276 -0.609
Residual    1.3100399       

Fixed effects: distance ~ age 
                Value Std.Error DF   t-value p-value
(Intercept) 16.761111 0.7752461 80 21.620375       0
age          0.660185 0.0712533 80  9.265334       0
 Correlation: 
    (Intr)
age -0.848

Standardized Within-Group Residuals:
         Min           Q1          Med           Q3 
-3.223106013 -0.493760868  0.007316632  0.472151090 
         Max 
 3.916032745 

Number of Observations: 108
Number of Groups: 27 

lme> summary(fm2)
Linear mixed-effects model fit by REML
 Data: Orthodont 
       AIC      BIC    logLik
  447.5125 460.7823 -218.7563

Random effects:
 Formula: ~1 | Subject
        (Intercept) Residual
StdDev:    1.807425 1.431592

Fixed effects: distance ~ age + Sex 
                Value Std.Error DF   t-value p-value
(Intercept) 17.706713 0.8339225 80 21.233044  0.0000
age          0.660185 0.0616059 80 10.716263  0.0000
SexFemale   -2.321023 0.7614168 25 -3.048294  0.0054
 Correlation: 
          (Intr) age   
age       -0.813       
SexFemale -0.372  0.000

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3 
-3.74889609 -0.55034466 -0.02516628  0.45341781 
        Max 
 3.65746539 

Number of Observations: 108
Number of Groups: 27 
> ls()
[1] "fm1"          "fm2"          "ozone"       
[4] "repo"         "updatePrompt"
> anova(fm1,fm2)
    Model df      AIC      BIC    logLik   Test  L.Ratio
fm1     1  6 454.6367 470.6173 -221.3183                
fm2     2  5 447.5125 460.7823 -218.7562 1 vs 2 5.124178
    p-value
fm1        
fm2  0.0236
Warning message:
In anova.lme(fm1, fm2) :
  fitted objects with different fixed effects. REML comparisons are not meaningful.
> anova(fm1,fm2)
    Model df      AIC      BIC    logLik   Test  L.Ratio p-value
fm1     1  6 454.6367 470.6173 -221.3183                        
fm2     2  5 447.5125 460.7823 -218.7562 1 vs 2 5.124178  0.0236
Warning message:
In anova.lme(fm1, fm2) :
  fitted objects with different fixed effects. REML comparisons are not meaningful.
> 
> 
> 
> 
> 
> 
> 
> 
> anova(fm1,fm2)
    Model df      AIC      BIC    logLik   Test  L.Ratio p-value
fm1     1  6 454.6367 470.6173 -221.3183                        
fm2     2  5 447.5125 460.7823 -218.7562 1 vs 2 5.124178  0.0236
Warning message:
In anova.lme(fm1, fm2) :
  fitted objects with different fixed effects. REML comparisons are not meaningful.
> example(aov)

aov> ## From Venables and Ripley (2002) p.165.
aov> 
aov> ## Set orthogonal contrasts.
aov> op <- options(contrasts = c("contr.helmert", "contr.poly"))

aov> ( npk.aov <- aov(yield ~ block + N*P*K, npk) )
Call:
   aov(formula = yield ~ block + N * P * K, data = npk)

Terms:
                   block        N        P        K      N:P      N:K      P:K
Sum of Squares  343.2950 189.2817   8.4017  95.2017  21.2817  33.1350   0.4817
Deg. of Freedom        5        1        1        1        1        1        1
                Residuals
Sum of Squares   185.2867
Deg. of Freedom        12

Residual standard error: 3.929447
1 out of 13 effects not estimable
Estimated effects are balanced

aov> ## No test: 
aov> summary(npk.aov)
            Df Sum Sq Mean Sq F value  Pr(>F)   
block        5  343.3   68.66   4.447 0.01594 * 
N            1  189.3  189.28  12.259 0.00437 **
P            1    8.4    8.40   0.544 0.47490   
K            1   95.2   95.20   6.166 0.02880 * 
N:P          1   21.3   21.28   1.378 0.26317   
N:K          1   33.1   33.14   2.146 0.16865   
P:K          1    0.5    0.48   0.031 0.86275   
Residuals   12  185.3   15.44                   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

aov> ## End(No test)
aov> coefficients(npk.aov)
(Intercept)      block1      block2      block3      block4      block5 
 54.8750000   1.7125000   1.6791667  -1.8229167  -1.0137500   0.2950000 
         N1          P1          K1       N1:P1       N1:K1       P1:K1 
  2.8083333  -0.5916667  -1.9916667  -0.9416667  -1.1750000   0.1416667 

aov> ## to show the effects of re-ordering terms contrast the two fits
aov> aov(yield ~ block + N * P + K, npk)
Call:
   aov(formula = yield ~ block + N * P + K, data = npk)

Terms:
                   block        N        P        K      N:P Residuals
Sum of Squares  343.2950 189.2817   8.4017  95.2017  21.2817  218.9033
Deg. of Freedom        5        1        1        1        1        14

Residual standard error: 3.954232
Estimated effects are balanced

aov> aov(terms(yield ~ block + N * P + K, keep.order = TRUE), npk)
Call:
   aov(formula = terms(yield ~ block + N * P + K, keep.order = TRUE), 
    data = npk)

Terms:
                   block        N        P      N:P        K Residuals
Sum of Squares  343.2950 189.2817   8.4017  21.2817  95.2017  218.9033
Deg. of Freedom        5        1        1        1        1        14

Residual standard error: 3.954232
Estimated effects are balanced

aov> ## as a test, not particularly sensible statistically
aov> npk.aovE <- aov(yield ~  N*P*K + Error(block), npk)

aov> npk.aovE

Call:
aov(formula = yield ~ N * P * K + Error(block), data = npk)

Grand Mean: 54.875

Stratum 1: block

Terms:
                    N:P:K Residuals
Sum of Squares   37.00167 306.29333
Deg. of Freedom         1         4

Residual standard error: 8.750619
Estimated effects are balanced

Stratum 2: Within

Terms:
                        N         P         K       N:P       N:K       P:K
Sum of Squares  189.28167   8.40167  95.20167  21.28167  33.13500   0.48167
Deg. of Freedom         1         1         1         1         1         1
                Residuals
Sum of Squares  185.28667
Deg. of Freedom        12

Residual standard error: 3.929447
Estimated effects are balanced

aov> summary(npk.aovE)

Error: block
          Df Sum Sq Mean Sq F value Pr(>F)
N:P:K      1   37.0   37.00   0.483  0.525
Residuals  4  306.3   76.57               

Error: Within
          Df Sum Sq Mean Sq F value  Pr(>F)   
N          1 189.28  189.28  12.259 0.00437 **
P          1   8.40    8.40   0.544 0.47490   
K          1  95.20   95.20   6.166 0.02880 * 
N:P        1  21.28   21.28   1.378 0.26317   
N:K        1  33.14   33.14   2.146 0.16865   
P:K        1   0.48    0.48   0.031 0.86275   
Residuals 12 185.29   15.44                   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

aov> options(op)  # reset to previous
> npk.aov
Call:
   aov(formula = yield ~ block + N * P * K, data = npk)

Terms:
                   block        N        P        K      N:P      N:K      P:K
Sum of Squares  343.2950 189.2817   8.4017  95.2017  21.2817  33.1350   0.4817
Deg. of Freedom        5        1        1        1        1        1        1
                Residuals
Sum of Squares   185.2867
Deg. of Freedom        12

Residual standard error: 3.929447
1 out of 13 effects not estimable
Estimated effects are balanced
> npk.aov$call
aov(formula = yield ~ block + N * P * K, data = npk)
> npk.lm <- lm(yield ~block + N *p*K, data=npk)
Error in eval(expr, envir, enclos) : object 'p' not found
> npk.lm <- lm(yield ~block + N *P*K, data=npk)
> anova(npk.aov)
Analysis of Variance Table

Response: yield
          Df Sum Sq Mean Sq F value   Pr(>F)   
block      5 343.29  68.659  4.4467 0.015939 * 
N          1 189.28 189.282 12.2587 0.004372 **
P          1   8.40   8.402  0.5441 0.474904   
K          1  95.20  95.202  6.1657 0.028795 * 
N:P        1  21.28  21.282  1.3783 0.263165   
N:K        1  33.14  33.135  2.1460 0.168648   
P:K        1   0.48   0.482  0.0312 0.862752   
Residuals 12 185.29  15.441                    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> anova(npk.lm)
Analysis of Variance Table

Response: yield
          Df Sum Sq Mean Sq F value   Pr(>F)   
block      5 343.29  68.659  4.4467 0.015939 * 
N          1 189.28 189.282 12.2587 0.004372 **
P          1   8.40   8.402  0.5441 0.474904   
K          1  95.20  95.202  6.1657 0.028795 * 
N:P        1  21.28  21.282  1.3783 0.263165   
N:K        1  33.14  33.135  2.1460 0.168648   
P:K        1   0.48   0.482  0.0312 0.862752   
Residuals 12 185.29  15.441                    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> summary(npk.aov)
            Df Sum Sq Mean Sq F value  Pr(>F)   
block        5  343.3   68.66   4.447 0.01594 * 
N            1  189.3  189.28  12.259 0.00437 **
P            1    8.4    8.40   0.544 0.47490   
K            1   95.2   95.20   6.166 0.02880 * 
N:P          1   21.3   21.28   1.378 0.26317   
N:K          1   33.1   33.14   2.146 0.16865   
P:K          1    0.5    0.48   0.031 0.86275   
Residuals   12  185.3   15.44                   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> summary(npk.lm)

Call:
lm(formula = yield ~ block + N * P * K, data = npk)

Residuals:
    Min      1Q  Median      3Q     Max 
-5.3000 -1.6833  0.1583  1.9979  4.4750 

Coefficients: (1 not defined because of singularities)
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  51.8250     2.7785  18.652 3.15e-10 ***
block2        3.4250     2.7785   1.233  0.24131    
block3        6.7500     2.7785   2.429  0.03177 *  
block4       -3.9000     2.7785  -1.404  0.18578    
block5       -3.5000     2.7785  -1.260  0.23174    
block6        2.3250     2.7785   0.837  0.41907    
N1            9.8500     2.7785   3.545  0.00403 ** 
P1            0.4167     2.7785   0.150  0.88329    
K1           -1.9167     2.7785  -0.690  0.50344    
N1:P1        -3.7667     3.2084  -1.174  0.26317    
N1:K1        -4.7000     3.2084  -1.465  0.16865    
P1:K1         0.5667     3.2084   0.177  0.86275    
N1:P1:K1          NA         NA      NA       NA    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 3.929 on 12 degrees of freedom
Multiple R-squared:  0.7886,	Adjusted R-squared:  0.5948 
F-statistic: 4.069 on 11 and 12 DF,  p-value: 0.01156

> 
> 
> 
> library(mgcv)
> example(gam)

gam> ## see also examples in ?gam.models (e.g. 'by' variables, 
gam> ## random effects and tricks for large binary datasets)
gam> 
gam> library(mgcv)

gam> set.seed(2) ## simulate some data... 

gam> dat <- gamSim(1,n=400,dist="normal",scale=2)
Gu & Wahba 4 term additive model

gam> b <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat)

gam> summary(b)

Family: gaussian 
Link function: identity 

Formula:
y ~ s(x0) + s(x1) + s(x2) + s(x3)

Parametric coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  7.83328    0.09878    79.3   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Approximate significance of smooth terms:
        edf Ref.df      F  p-value    
s(x0) 2.500  3.115  6.921 0.000129 ***
s(x1) 2.401  2.984 81.858  < 2e-16 ***
s(x2) 7.698  8.564 88.158  < 2e-16 ***
s(x3) 1.000  1.000  4.343 0.037806 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) =  0.715   Deviance explained = 72.5%
GCV = 4.0505  Scale est. = 3.9027    n = 400

gam> plot(b,pages=1,residuals=TRUE)  ## show partial residuals
Hit <Return> to see next plot: 

gam> plot(b,pages=1,seWithMean=TRUE) ## `with intercept' CIs
Hit <Return> to see next plot: 

gam> ## run some basic model checks, including checking
gam> ## smoothing basis dimensions...
gam> gam.check(b)
Hit <Return> to see next plot: 
Hit <Return> to see next plot: 
Hit <Return> to see next plot: 
Hit <Return> to see next plot: 

Method: GCV   Optimizer: magic
Smoothing parameter selection converged after 12 iterations.
The RMS GCV score gradient at convergence was 1.739918e-07 .
The Hessian was positive definite.
Model rank =  37 / 37 

Basis dimension (k) checking results. Low p-value (k-index<1) may
indicate that k is too low, especially if edf is close to k'.

         k'   edf k-index p-value
s(x0) 9.000 2.500   1.045    0.77
s(x1) 9.000 2.401   1.027    0.64
s(x2) 9.000 7.698   0.969    0.30
s(x3) 9.000 1.000   1.030    0.74

gam> ## same fit in two parts .....
gam> G <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),fit=FALSE,data=dat)

gam> b <- gam(G=G)

gam> print(b)

Family: gaussian 
Link function: identity 

Formula:
y ~ s(x0) + s(x1) + s(x2) + s(x3)

Estimated degrees of freedom:
2.5 2.4 7.7 1.0  total = 14.6 

GCV score: 4.050519     

gam> ## 2 part fit enabling manipulation of smoothing parameters...
gam> G <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),fit=FALSE,data=dat,sp=b$sp)

gam> G$lsp0 <- log(b$sp*10) ## provide log of required sp vec

gam> gam(G=G) ## it's smoother

Family: gaussian 
Link function: identity 

Formula:
y ~ s(x0) + s(x1) + s(x2) + s(x3)

Estimated degrees of freedom:
1.43 1.39 5.20 1.00  total = 10.02 

GCV score: 4.365998     

gam> ## change the smoothness selection method to REML
gam> b0 <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat,method="REML")

gam> ## use alternative plotting scheme, and way intervals include
gam> ## smoothing parameter uncertainty...
gam> plot(b0,pages=1,scheme=1,unconditional=TRUE) 
Hit <Return> to see next plot: 

gam> ## Would a smooth interaction of x0 and x1 be better?
gam> ## Use tensor product smooth of x0 and x1, basis 
gam> ## dimension 49 (see ?te for details, also ?t2).
gam> bt <- gam(y~te(x0,x1,k=7)+s(x2)+s(x3),data=dat,
gam+           method="REML")

gam> plot(bt,pages=1) 
Hit <Return> to see next plot: 

gam> plot(bt,pages=1,scheme=2) ## alternative visualization
Hit <Return> to see next plot: 

gam> AIC(b0,bt) ## interaction worse than additive
         df      AIC
b0 17.68999 1698.504
bt 24.50265 1698.215

gam> ## Alternative: test for interaction with a smooth ANOVA 
gam> ## decomposition (this time between x2 and x1)
gam> bt <- gam(y~s(x0)+s(x1)+s(x2)+s(x3)+ti(x1,x2,k=6),
gam+             data=dat,method="REML")

gam> summary(bt)

Family: gaussian 
Link function: identity 

Formula:
y ~ s(x0) + s(x1) + s(x2) + s(x3) + ti(x1, x2, k = 6)

Parametric coefficients:
            Estimate Std. Error t value
(Intercept)  7.83338    0.09883   79.26
            Pr(>|t|)    
(Intercept)   <2e-16 ***
---
Signif. codes:  
0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Approximate significance of smooth terms:
            edf Ref.df      F  p-value    
s(x0)     3.013  3.744  6.226 0.000133 ***
s(x1)     2.840  3.524 69.568  < 2e-16 ***
s(x2)     8.012  8.736 85.971  < 2e-16 ***
s(x3)     1.000  1.000  4.176 0.041664 *  
ti(x1,x2) 1.006  1.011  0.087 0.775150    
---
Signif. codes:  
0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) =  0.715   Deviance explained = 72.6%
-REML = 860.37  Scale est. = 3.9068    n = 400

gam> ## If it is believed that x0 and x1 are naturally on 
gam> ## the same scale, and should be treated isotropically 
gam> ## then could try...
gam> bs <- gam(y~s(x0,x1,k=40)+s(x2)+s(x3),data=dat,
gam+           method="REML")

gam> plot(bs,pages=1)
Hit <Return> to see next plot: 

gam> AIC(b0,bt,bs) ## additive still better. 
         df      AIC
b0 17.68999 1698.504
bt 18.79727 1700.592
bs 23.78889 1699.827

gam> ## Now do automatic terms selection as well
gam> b1 <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat,
gam+        method="REML",select=TRUE)

gam> plot(b1,pages=1)
Hit <Return> to see next plot: 

gam> ## set the smoothing parameter for the first term, estimate rest ...
gam> bp <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),sp=c(0.01,-1,-1,-1),data=dat)

gam> plot(bp,pages=1,scheme=1)
Hit <Return> to see next plot: 

gam> ## alternatively...
gam> bp <- gam(y~s(x0,sp=.01)+s(x1)+s(x2)+s(x3),data=dat)

gam> # set lower bounds on smoothing parameters ....
gam> bp<-gam(y~s(x0)+s(x1)+s(x2)+s(x3),
gam+         min.sp=c(0.001,0.01,0,10),data=dat) 

gam> print(b);print(bp)

Family: gaussian 
Link function: identity 

Formula:
y ~ s(x0) + s(x1) + s(x2) + s(x3)

Estimated degrees of freedom:
2.5 2.4 7.7 1.0  total = 14.6 

GCV score: 4.050519     

Family: gaussian 
Link function: identity 

Formula:
y ~ s(x0) + s(x1) + s(x2) + s(x3)

Estimated degrees of freedom:
2.5 2.4 7.7 1.0  total = 14.6 

GCV score: 4.050519     

gam> # same with REML
gam> bp<-gam(y~s(x0)+s(x1)+s(x2)+s(x3),
gam+         min.sp=c(0.1,0.1,0,10),data=dat,method="REML") 

gam> print(b0);print(bp)

Family: gaussian 
Link function: identity 

Formula:
y ~ s(x0) + s(x1) + s(x2) + s(x3)

Estimated degrees of freedom:
3.02 2.84 8.02 1.00  total = 15.89 

REML score: 861.1296     

Family: gaussian 
Link function: identity 

Formula:
y ~ s(x0) + s(x1) + s(x2) + s(x3)

Estimated degrees of freedom:
3.02 2.84 8.02 1.00  total = 15.89 

REML score: 861.1294     

gam> ## now a GAM with 3df regression spline term & 2 penalized terms
gam> 
gam> b0 <- gam(y~s(x0,k=4,fx=TRUE,bs="tp")+s(x1,k=12)+s(x2,k=15),data=dat)

gam> plot(b0,pages=1)
Hit <Return> to see next plot: 

gam> ## now simulate poisson data...
gam> dat <- gamSim(1,n=2000,dist="poisson",scale=.1)
Gu & Wahba 4 term additive model

gam> ## use "cr" basis to save time, with 2000 data...
gam> b2<-gam(y~s(x0,bs="cr")+s(x1,bs="cr")+s(x2,bs="cr")+
gam+         s(x3,bs="cr"),family=poisson,data=dat,method="REML")

gam> plot(b2,pages=1)
Hit <Return> to see next plot: 

gam> ## drop x3, but initialize sp's from previous fit, to 
gam> ## save more time...
gam> 
gam> b2a<-gam(y~s(x0,bs="cr")+s(x1,bs="cr")+s(x2,bs="cr"),
gam+          family=poisson,data=dat,method="REML",
gam+          in.out=list(sp=b2$sp[1:3],scale=1))

gam> par(mfrow=c(2,2))

gam> plot(b2a)
Hit <Return> to see next plot: 

gam> par(mfrow=c(1,1))

gam> ## similar example using performance iteration
gam> dat <- gamSim(1,n=400,dist="poisson",scale=.25)
Gu & Wahba 4 term additive model

gam> b3<-gam(y~s(x0)+s(x1)+s(x2)+s(x3),family=poisson,
gam+         data=dat,optimizer="perf")

gam> plot(b3,pages=1)
Hit <Return> to see next plot: 

gam> ## repeat using GACV as in Wood 2008...
gam> 
gam> b4<-gam(y~s(x0)+s(x1)+s(x2)+s(x3),family=poisson,
gam+         data=dat,method="GACV.Cp",scale=-1)

gam> plot(b4,pages=1)
Hit <Return> to see next plot: 

gam> ## repeat using REML as in Wood 2011...
gam> 
gam> b5<-gam(y~s(x0)+s(x1)+s(x2)+s(x3),family=poisson,
gam+         data=dat,method="REML")

gam> plot(b5,pages=1)
Hit <Return> to see next plot: 

gam> ## a binary example (see ?gam.models for large dataset version)...
gam> 
gam> dat <- gamSim(1,n=400,dist="binary",scale=.33)
Gu & Wahba 4 term additive model

gam> lr.fit <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),family=binomial,
gam+               data=dat,method="REML")

gam> ## plot model components with truth overlaid in red
gam> op <- par(mfrow=c(2,2))

gam> fn <- c("f0","f1","f2","f3");xn <- c("x0","x1","x2","x3")

gam> for (k in 1:4) {
gam+   plot(lr.fit,residuals=TRUE,select=k)
gam+   ff <- dat[[fn[k]]];xx <- dat[[xn[k]]]
gam+   ind <- sort.int(xx,index.return=TRUE)$ix
gam+   lines(xx[ind],(ff-mean(ff))[ind]*.33,col=2)
gam+ }
Hit <Return> to see next plot: 

gam> par(op)

gam> anova(lr.fit)

Family: binomial 
Link function: logit 

Formula:
y ~ s(x0) + s(x1) + s(x2) + s(x3)

Approximate significance of smooth terms:
        edf Ref.df Chi.sq  p-value
s(x0) 2.114  2.635  3.948 0.302533
s(x1) 2.267  2.826 19.929 0.000161
s(x2) 5.889  7.032 49.115 2.31e-08
s(x3) 1.950  2.435  3.118 0.238012

gam> lr.fit1 <- gam(y~s(x0)+s(x1)+s(x2),family=binomial,
gam+                data=dat,method="REML")

gam> lr.fit2 <- gam(y~s(x1)+s(x2),family=binomial,
gam+                data=dat,method="REML")

gam> AIC(lr.fit,lr.fit1,lr.fit2)
              df      AIC
lr.fit  15.92793 429.0081
lr.fit1 13.46763 428.7897
lr.fit2 10.55142 427.6818

gam> ## For a Gamma example, see ?summary.gam...
gam> 
gam> ## For inverse Gaussian, see ?rig
gam> 
gam> ## now 2D smoothing...
gam> 
gam> eg <- gamSim(2,n=500,scale=.1)
Bivariate smoothing example

gam> attach(eg)

gam> op <- par(mfrow=c(2,2),mar=c(4,4,1,1))

gam> contour(truth$x,truth$z,truth$f) ## contour truth
Hit <Return> to see next plot: 

gam> b4 <- gam(y~s(x,z),data=data) ## fit model

gam> fit1 <- matrix(predict.gam(b4,pr,se=FALSE),40,40)

gam> contour(truth$x,truth$z,fit1)   ## contour fit

gam> persp(truth$x,truth$z,truth$f)    ## persp truth

gam> vis.gam(b4)                     ## persp fit

gam> detach(eg)

gam> par(op)

gam> ## Not run: 
gam> ##D ##################################################
gam> ##D ## largish dataset example with user defined knots
gam> ##D ##################################################
gam> ##D 
gam> ##D par(mfrow=c(2,2))
gam> ##D n <- 5000
gam> ##D eg <- gamSim(2,n=n,scale=.5)
gam> ##D attach(eg)
gam> ##D 
gam> ##D ind<-sample(1:n,200,replace=FALSE)
gam> ##D b5<-gam(y~s(x,z,k=40),data=data,
gam> ##D         knots=list(x=data$x[ind],z=data$z[ind]))
gam> ##D ## various visualizations
gam> ##D vis.gam(b5,theta=30,phi=30)
gam> ##D plot(b5)
gam> ##D plot(b5,scheme=1,theta=50,phi=20)
gam> ##D plot(b5,scheme=2)
gam> ##D 
gam> ##D par(mfrow=c(1,1))
gam> ##D ## and a pure "knot based" spline of the same data
gam> ##D b6<-gam(y~s(x,z,k=64),data=data,knots=list(x= rep((1:8-0.5)/8,8),
gam> ##D         z=rep((1:8-0.5)/8,rep(8,8))))
gam> ##D vis.gam(b6,color="heat",theta=30,phi=30)
gam> ##D 
gam> ##D ## varying the default large dataset behaviour via `xt'
gam> ##D b7 <- gam(y~s(x,z,k=40,xt=list(max.knots=500,seed=2)),data=data)
gam> ##D vis.gam(b7,theta=30,phi=30)
gam> ##D detach(eg)
gam> ## End(Not run)
gam> 
gam> 
gam> 
> 
